{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def parse_yolo_label(label_path):\n",
    "    \"\"\"\n",
    "    YOLOフォーマットのラベルを解析する関数\n",
    "    \"\"\"\n",
    "    keypoints_list = []\n",
    "    class_ids = []\n",
    "    bboxes = []\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                bbox = [float(x) for x in parts[1:5]]\n",
    "    \n",
    "                keypoints = []\n",
    "                for i in range(5, len(parts), 3):\n",
    "                    if i+2 < len(parts):\n",
    "                        kp = [float(parts[i]), float(parts[i+1]), int(parts[i+2])]\n",
    "                        keypoints.append(kp)\n",
    "                \n",
    "                class_ids.append(class_id)\n",
    "                bboxes.append(bbox)\n",
    "                keypoints_list.append(np.array(keypoints))\n",
    "    \n",
    "    return class_ids, bboxes, keypoints_list\n",
    "\n",
    "def calculate_pcp(pred_keypoints, gt_keypoints, visible_threshold=0, threshold=0.5):\n",
    "    visible_indices = np.where(gt_keypoints[:, 2] > visible_threshold)[0]\n",
    "    \n",
    "    if len(visible_indices) < 2:\n",
    "        return 0, 0, 0 \n",
    "\n",
    "    keypoint_pairs = []\n",
    "    for i in range(len(visible_indices)-1):\n",
    "        keypoint_pairs.append((visible_indices[i], visible_indices[i+1]))\n",
    "    \n",
    "    if not keypoint_pairs:\n",
    "        return 0, 0, 0  \n",
    "    max_dist = 0\n",
    "    for i in range(len(visible_indices)):\n",
    "        for j in range(i+1, len(visible_indices)):\n",
    "            idx1, idx2 = visible_indices[i], visible_indices[j]\n",
    "            dist = np.sqrt(((gt_keypoints[idx1, :2] - gt_keypoints[idx2, :2]) ** 2).sum())\n",
    "            max_dist = max(max_dist, dist)\n",
    "    \n",
    "    if max_dist == 0:\n",
    "        return 0, 0, 0  \n",
    "    correct_parts = 0\n",
    "    valid_parts = len(keypoint_pairs)  \n",
    "    for joint1, joint2 in keypoint_pairs:\n",
    "        if joint1 >= len(pred_keypoints) or joint2 >= len(pred_keypoints):\n",
    "            continue\n",
    " \n",
    "        dist1 = np.sqrt(((pred_keypoints[joint1, :2] - gt_keypoints[joint1, :2]) ** 2).sum())\n",
    "        dist2 = np.sqrt(((pred_keypoints[joint2, :2] - gt_keypoints[joint2, :2]) ** 2).sum())\n",
    "      \n",
    "        norm_dist1 = dist1 / max_dist\n",
    "        norm_dist2 = dist2 / max_dist\n",
    " \n",
    "        part_length = np.sqrt(((gt_keypoints[joint1, :2] - gt_keypoints[joint2, :2]) ** 2).sum())\n",
    "        half_part_length = part_length / 2\n",
    "        \n",
    "        if (norm_dist1 <= threshold and norm_dist2 <= threshold and\n",
    "            dist1 <= half_part_length and dist2 <= half_part_length):\n",
    "            correct_parts += 1\n",
    "\n",
    "    pcp = correct_parts / max(valid_parts, 1) \n",
    "    return pcp, correct_parts, valid_parts\n",
    "\n",
    "# def calculate_pcp(pred_keypoints, gt_keypoints, visible_threshold=0, threshold=0.5):\n",
    "#     visible_indices = np.where(gt_keypoints[:, 2] > visible_threshold)[0]\n",
    "    \n",
    "#     if len(visible_indices) < 2:\n",
    "#         return 0, 0, 0 \n",
    "\n",
    "#     keypoint_pairs = []\n",
    "#     for i in range(len(visible_indices)-1):\n",
    "#         keypoint_pairs.append((visible_indices[i], visible_indices[i+1]))\n",
    "    \n",
    "#     if not keypoint_pairs:\n",
    "#         return 0, 0, 0  \n",
    "#     max_dist = 0\n",
    "#     for i in range(len(visible_indices)):\n",
    "#         for j in range(i+1, len(visible_indices)):\n",
    "#             idx1, idx2 = visible_indices[i], visible_indices[j]\n",
    "#             dist = np.sqrt(((gt_keypoints[idx1, :2] - gt_keypoints[idx2, :2]) ** 2).sum())\n",
    "#             max_dist = max(max_dist, dist)\n",
    "    \n",
    "#     if max_dist == 0:\n",
    "#         return 0, 0, 0  \n",
    "#     correct_parts = 0\n",
    "#     valid_parts = len(keypoint_pairs)  \n",
    "#     for joint1, joint2 in keypoint_pairs:\n",
    "#         if joint1 >= len(pred_keypoints) or joint2 >= len(pred_keypoints):\n",
    "#             continue\n",
    "            \n",
    "#         dist1 = np.sqrt(((pred_keypoints[joint1, :2] - gt_keypoints[joint1, :2]) ** 2).sum())\n",
    "#         dist2 = np.sqrt(((pred_keypoints[joint2, :2] - gt_keypoints[joint2, :2]) ** 2).sum())\n",
    "      \n",
    "#         norm_dist1 = dist1 / max_dist\n",
    "#         norm_dist2 = dist2 / max_dist\n",
    "        \n",
    "#         if norm_dist1 <= threshold and norm_dist2 <= threshold:\n",
    "#             correct_parts += 1\n",
    "\n",
    "#     pcp = correct_parts / max(valid_parts, 1) \n",
    "#     return pcp, correct_parts, valid_parts\n",
    "\n",
    "def evaluate_on_dataset(model, dataset_path, img_size=640, threshold=0.5):\n",
    "    images_path = os.path.join(dataset_path, 'images')\n",
    "    labels_path = os.path.join(dataset_path, 'labels')\n",
    "    \n",
    "    total_correct_parts = 0\n",
    "    total_valid_parts = 0\n",
    "    pcp_scores = []\n",
    "    class_stats = {0: {'correct': 0, 'valid': 0, 'scores': []}, \n",
    "                   1: {'correct': 0, 'valid': 0, 'scores': []}}\n",
    "\n",
    "    results_details = []\n",
    "\n",
    "    image_files = glob.glob(os.path.join(images_path, '*.jpg')) + \\\n",
    "                 glob.glob(os.path.join(images_path, '*.jpeg')) + \\\n",
    "                 glob.glob(os.path.join(images_path, '*.png'))\n",
    "    \n",
    "    for img_path in tqdm(image_files):\n",
    "        base_name = os.path.basename(img_path)\n",
    "        name_without_ext = os.path.splitext(base_name)[0]\n",
    "        label_file = os.path.join(labels_path, name_without_ext + '.txt')\n",
    "        if not os.path.exists(label_file):\n",
    "            continue\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue     \n",
    "        height, width = img.shape[:2]\n",
    "    \n",
    "        try:\n",
    "            gt_classes, gt_bboxes, gt_keypoints_list = parse_yolo_label(label_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing label file {label_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if not gt_classes:\n",
    "            continue\n",
    "      \n",
    "        results = model(img, verbose=False)\n",
    "        \n",
    "        if len(results[0].keypoints.data) == 0:\n",
    "            continue\n",
    "\n",
    "        for gt_idx, (gt_class, gt_bbox, gt_keypoints) in enumerate(zip(gt_classes, gt_bboxes, gt_keypoints_list)):\n",
    "            gt_x_center, gt_y_center, gt_width, gt_height = gt_bbox\n",
    "            gt_x_center *= width\n",
    "            gt_y_center *= height\n",
    "            gt_width *= width\n",
    "            gt_height *= height\n",
    "            \n",
    "            gt_x1 = gt_x_center - gt_width / 2\n",
    "            gt_y1 = gt_y_center - gt_height / 2\n",
    "            gt_x2 = gt_x_center + gt_width / 2\n",
    "            gt_y2 = gt_y_center + gt_height / 2\n",
    "            \n",
    "            for i in range(len(gt_keypoints)):\n",
    "                if gt_keypoints[i, 2] > 0:\n",
    "                    gt_keypoints[i, 0] *= width\n",
    "                    gt_keypoints[i, 1] *= height\n",
    "            \n",
    "            best_match_idx = -1\n",
    "            best_iou = 0\n",
    "            \n",
    "            for pred_idx, box in enumerate(results[0].boxes.xyxy.cpu().numpy()):\n",
    "                pred_x1, pred_y1, pred_x2, pred_y2 = box\n",
    "                \n",
    "                inter_x1 = max(gt_x1, pred_x1)\n",
    "                inter_y1 = max(gt_y1, pred_y1)\n",
    "                inter_x2 = min(gt_x2, pred_x2)\n",
    "                inter_y2 = min(gt_y2, pred_y2)\n",
    "                \n",
    "                if inter_x1 < inter_x2 and inter_y1 < inter_y2:\n",
    "                    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)\n",
    "                    gt_area = (gt_x2 - gt_x1) * (gt_y2 - gt_y1)\n",
    "                    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "                    union_area = gt_area + pred_area - inter_area\n",
    "                    iou = inter_area / union_area\n",
    "                    \n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_match_idx = pred_idx\n",
    "\n",
    "            if best_match_idx >= 0 and best_iou > 0.5: \n",
    "                pred_class = int(results[0].boxes.cls[best_match_idx].cpu().numpy().item())\n",
    "                pred_keypoints = results[0].keypoints.data[best_match_idx].cpu().numpy()\n",
    "                \n",
    "                # PCPを計算\n",
    "                pcp, correct, valid = calculate_pcp(pred_keypoints, gt_keypoints, threshold=threshold)\n",
    "                \n",
    "                if valid > 0:\n",
    "                    total_correct_parts += correct\n",
    "                    total_valid_parts += valid\n",
    "                    pcp_scores.append(pcp)\n",
    "\n",
    "                    class_stats[gt_class]['correct'] += correct\n",
    "                    class_stats[gt_class]['valid'] += valid\n",
    "                    class_stats[gt_class]['scores'].append(pcp)\n",
    "                    \n",
    "                    # 結果詳細を保存\n",
    "                    results_details.append({\n",
    "                        'image': base_name,\n",
    "                        'gt_class': gt_class,\n",
    "                        'pred_class': pred_class,\n",
    "                        'iou': best_iou,\n",
    "                        'pcp': pcp,\n",
    "                        'correct_parts': correct,\n",
    "                        'valid_parts': valid\n",
    "                    })\n",
    "    \n",
    "    overall_pcp = total_correct_parts / max(total_valid_parts, 1)\n",
    "    class_pcps = {}\n",
    "    for cls, stats in class_stats.items():\n",
    "        cls_pcp = stats['correct'] / max(stats['valid'], 1)\n",
    "        mean_pcp = np.mean(stats['scores']) if stats['scores'] else 0\n",
    "        class_pcps[cls] = {\n",
    "            'pcp': cls_pcp,\n",
    "            'mean_pcp': mean_pcp,\n",
    "            'count': len(stats['scores'])\n",
    "        }\n",
    "\n",
    "    details_df = pd.DataFrame(results_details)\n",
    "    \n",
    "    return overall_pcp, pcp_scores, class_pcps, details_df\n",
    "\n",
    "def main():\n",
    "    model_path = '../../AI_aug_gen/__output__/06_YOLOv8_Pose/1211_leafBlock/yolov8n-pose/20241211-02304906_yolov8n-pose_1211_lb_1000_n1050_kpt/weights/best.pt'\n",
    "    model = YOLO(model_path)\n",
    "    dataset_path = '../../AI_aug_gen/__dataset__/06_YOLOv8_Pose/1211_leafBlock_500/1211_lb_500_n550_kpt/test/'\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    class_names = {0: \"クラス0\", 1: \"grape_cane\"}\n",
    "\n",
    "    all_results = {}\n",
    "    for threshold in thresholds:\n",
    "        print(f'Evaluating with threshold: {threshold}')\n",
    "        overall_pcp, pcp_scores, class_pcps, details_df = evaluate_on_dataset(\n",
    "            model, dataset_path, threshold=threshold)\n",
    "\n",
    "        details_df.to_csv(f'pcp_details_threshold_{threshold}.csv', index=False)\n",
    "        \n",
    "        all_results[threshold] = {\n",
    "            'overall_pcp': overall_pcp,\n",
    "            'mean_pcp': np.mean(pcp_scores) if pcp_scores else 0,\n",
    "            'median_pcp': np.median(pcp_scores) if pcp_scores else 0,\n",
    "            'num_samples': len(pcp_scores),\n",
    "            'class_pcps': class_pcps\n",
    "        }\n",
    "        \n",
    "        print(f'  Overall PCP: {overall_pcp:.4f}')\n",
    "        print(f'  Mean PCP: {all_results[threshold][\"mean_pcp\"]:.4f}')\n",
    "        print(f'  Median PCP: {all_results[threshold][\"median_pcp\"]:.4f}')\n",
    "        print(f'  Samples: {all_results[threshold][\"num_samples\"]}')\n",
    "        \n",
    "        for cls, stats in class_pcps.items():\n",
    "            print(f'  Class {class_names[cls]}:')\n",
    "            print(f'    PCP: {stats[\"pcp\"]:.4f}')\n",
    "            print(f'    Mean PCP: {stats[\"mean_pcp\"]:.4f}')\n",
    "            print(f'    Count: {stats[\"count\"]}')\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(thresholds, [all_results[t]['overall_pcp'] for t in thresholds], marker='o', label='Overall PCP')\n",
    "    plt.plot(thresholds, [all_results[t]['mean_pcp'] for t in thresholds], marker='s', label='Mean PCP')\n",
    "    plt.plot(thresholds, [all_results[t]['median_pcp'] for t in thresholds], marker='^', label='Median PCP')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('PCP')\n",
    "    plt.title('Overall PCP vs Threshold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for cls in class_names:\n",
    "        if any(all_results[t]['class_pcps'].get(cls, {}).get('count', 0) > 0 for t in thresholds):\n",
    "            plt.plot(thresholds, \n",
    "                     [all_results[t]['class_pcps'].get(cls, {}).get('pcp', 0) for t in thresholds], \n",
    "                     marker='o', label=f'Class {class_names[cls]} PCP')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('PCP')\n",
    "    plt.title('Class-wise PCP vs Threshold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for cls in class_names:\n",
    "        if any(all_results[t]['class_pcps'].get(cls, {}).get('count', 0) > 0 for t in thresholds):\n",
    "            plt.plot(thresholds, \n",
    "                     [all_results[t]['class_pcps'].get(cls, {}).get('mean_pcp', 0) for t in thresholds], \n",
    "                     marker='s', label=f'Class {class_names[cls]} Mean PCP')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Mean PCP')\n",
    "    plt.title('Class-wise Mean PCP vs Threshold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.bar(range(len(class_names)), \n",
    "            [all_results[thresholds[0]]['class_pcps'].get(cls, {}).get('count', 0) for cls in class_names],\n",
    "            tick_label=[class_names[cls] for cls in class_names])\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Number of Evaluated Samples per Class')\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pcp_results.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    summary_df = []\n",
    "    for t in thresholds:\n",
    "        row = {\n",
    "            'Threshold': t,\n",
    "            'Overall_PCP': all_results[t]['overall_pcp'],\n",
    "            'Mean_PCP': all_results[t]['mean_pcp'],\n",
    "            'Median_PCP': all_results[t]['median_pcp'],\n",
    "            'Samples': all_results[t]['num_samples']\n",
    "        }\n",
    "        for cls in class_names:\n",
    "            if cls in all_results[t]['class_pcps']:\n",
    "                stats = all_results[t]['class_pcps'][cls]\n",
    "                row[f'Class_{class_names[cls]}_PCP'] = stats['pcp']\n",
    "                row[f'Class_{class_names[cls]}_Mean_PCP'] = stats['mean_pcp']\n",
    "                row[f'Class_{class_names[cls]}_Count'] = stats['count']\n",
    "        summary_df.append(row)\n",
    "    \n",
    "    pd.DataFrame(summary_df).to_csv('pcp_summary.csv', index=False)\n",
    "    print(\"Evaluation complete. Results saved to CSV files and plots.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
