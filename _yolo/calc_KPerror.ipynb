{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "最大誤差は512*sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def parse_yolo_label(label_path):\n",
    "    keypoints_list = []\n",
    "    class_ids = []\n",
    "    bboxes = []\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                bbox = [float(x) for x in parts[1:5]]\n",
    "    \n",
    "                keypoints = []\n",
    "                for i in range(5, len(parts), 3):\n",
    "                    if i+2 < len(parts):\n",
    "                        kp = [float(parts[i]), float(parts[i+1]), int(parts[i+2])]\n",
    "                        keypoints.append(kp)\n",
    "                \n",
    "                class_ids.append(class_id)\n",
    "                bboxes.append(bbox)\n",
    "                keypoints_list.append(np.array(keypoints))\n",
    "    \n",
    "    return class_ids, bboxes, keypoints_list\n",
    "\n",
    "def calculate_keypoint_errors(pred_keypoints, gt_keypoints, visible_threshold=0):\n",
    "    errors = []\n",
    "    visible_indices = np.where(gt_keypoints[:, 2] > visible_threshold)[0]\n",
    "    \n",
    "    for idx in visible_indices:\n",
    "        if idx < len(pred_keypoints):\n",
    "            # 各キーポイントのユークリッド距離を計算\n",
    "            error = np.sqrt(np.sum((pred_keypoints[idx, :2] - gt_keypoints[idx, :2]) ** 2))\n",
    "            errors.append({\n",
    "                'keypoint_idx': idx,\n",
    "                'error': error\n",
    "            })\n",
    "    \n",
    "    return errors, len(visible_indices)\n",
    "\n",
    "def evaluate_on_dataset(model, dataset_path, img_size=640):\n",
    "    images_path = os.path.join(dataset_path, 'images')\n",
    "    labels_path = os.path.join(dataset_path, 'labels')\n",
    "    \n",
    "    all_keypoint_errors = []\n",
    "    keypoint_errors_by_class = {0: [], 1: []}\n",
    "    \n",
    "    results_details = []\n",
    "\n",
    "    total_gt_keypoints = 0\n",
    "    total_visible_gt_keypoints = 0\n",
    "    total_detected_keypoints = 0\n",
    "    class_keypoint_stats = {0: {'total': 0, 'visible': 0, 'detected': 0},\n",
    "                           1: {'total': 0, 'visible': 0, 'detected': 0}}\n",
    "\n",
    "    image_files = glob.glob(os.path.join(images_path, '*.jpg')) + \\\n",
    "                 glob.glob(os.path.join(images_path, '*.jpeg')) + \\\n",
    "                 glob.glob(os.path.join(images_path, '*.png'))\n",
    "    \n",
    "    for img_path in tqdm(image_files):\n",
    "        base_name = os.path.basename(img_path)\n",
    "        name_without_ext = os.path.splitext(base_name)[0]\n",
    "        label_file = os.path.join(labels_path, name_without_ext + '.txt')\n",
    "        \n",
    "        if not os.path.exists(label_file):\n",
    "            continue\n",
    "            \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue     \n",
    "        height, width = img.shape[:2]\n",
    "    \n",
    "        try:\n",
    "            gt_classes, gt_bboxes, gt_keypoints_list = parse_yolo_label(label_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing label file {label_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if not gt_classes:\n",
    "            continue\n",
    "      \n",
    "        results = model(img, verbose=False)\n",
    "        \n",
    "        for gt_idx, (gt_class, gt_bbox, gt_keypoints) in enumerate(zip(gt_classes, gt_bboxes, gt_keypoints_list)):\n",
    "            total_gt_keypoints += len(gt_keypoints)\n",
    "            class_keypoint_stats[gt_class]['total'] += len(gt_keypoints)\n",
    "            \n",
    "            visible_keypoints = np.sum(gt_keypoints[:, 2] > 0)\n",
    "            total_visible_gt_keypoints += visible_keypoints\n",
    "            class_keypoint_stats[gt_class]['visible'] += visible_keypoints\n",
    "            \n",
    "            gt_x_center, gt_y_center, gt_width, gt_height = gt_bbox\n",
    "            gt_x_center *= width\n",
    "            gt_y_center *= height\n",
    "            gt_width *= width\n",
    "            gt_height *= height\n",
    "            \n",
    "            gt_x1 = gt_x_center - gt_width / 2\n",
    "            gt_y1 = gt_y_center - gt_height / 2\n",
    "            gt_x2 = gt_x_center + gt_width / 2\n",
    "            gt_y2 = gt_y_center + gt_height / 2\n",
    "            \n",
    "            for i in range(len(gt_keypoints)):\n",
    "                if gt_keypoints[i, 2] > 0:\n",
    "                    gt_keypoints[i, 0] *= width\n",
    "                    gt_keypoints[i, 1] *= height\n",
    "            \n",
    "            best_match_idx = -1\n",
    "            best_iou = 0\n",
    "            \n",
    "            if len(results[0].keypoints.data) > 0:\n",
    "                for pred_idx, box in enumerate(results[0].boxes.xyxy.cpu().numpy()):\n",
    "                    pred_x1, pred_y1, pred_x2, pred_y2 = box\n",
    "                    \n",
    "                    inter_x1 = max(gt_x1, pred_x1)\n",
    "                    inter_y1 = max(gt_y1, pred_y1)\n",
    "                    inter_x2 = min(gt_x2, pred_x2)\n",
    "                    inter_y2 = min(gt_y2, pred_y2)\n",
    "                    \n",
    "                    if inter_x1 < inter_x2 and inter_y1 < inter_y2:\n",
    "                        inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)\n",
    "                        gt_area = (gt_x2 - gt_x1) * (gt_y2 - gt_y1)\n",
    "                        pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "                        union_area = gt_area + pred_area - inter_area\n",
    "                        iou = inter_area / union_area\n",
    "                        \n",
    "                        if iou > best_iou:\n",
    "                            best_iou = iou\n",
    "                            best_match_idx = pred_idx\n",
    "\n",
    "            if best_match_idx >= 0 and best_iou > 0.5: \n",
    "                pred_class = int(results[0].boxes.cls[best_match_idx].cpu().numpy().item())\n",
    "                pred_keypoints = results[0].keypoints.data[best_match_idx].cpu().numpy()\n",
    "                \n",
    "                errors, visible_count = calculate_keypoint_errors(pred_keypoints, gt_keypoints)\n",
    "               \n",
    "                detected_count = len(errors)\n",
    "                total_detected_keypoints += detected_count\n",
    "                class_keypoint_stats[gt_class]['detected'] += detected_count\n",
    "                \n",
    "                for error_info in errors:\n",
    "                    error_info['image'] = base_name\n",
    "                    error_info['gt_class'] = gt_class\n",
    "                    error_info['pred_class'] = pred_class\n",
    "                    error_info['iou'] = best_iou\n",
    "                    all_keypoint_errors.append(error_info)\n",
    "                    keypoint_errors_by_class[gt_class].append(error_info)\n",
    "                    \n",
    "                    results_details.append(error_info)\n",
    "    \n",
    "    details_df = pd.DataFrame(results_details)\n",
    "    \n",
    "    keypoint_stats = {\n",
    "        'total_gt_keypoints': total_gt_keypoints,\n",
    "        'total_visible_gt_keypoints': total_visible_gt_keypoints,\n",
    "        'total_detected_keypoints': total_detected_keypoints,\n",
    "        'class_stats': class_keypoint_stats\n",
    "    }\n",
    "    \n",
    "    return all_keypoint_errors, keypoint_errors_by_class, details_df, keypoint_stats\n",
    "\n",
    "def visualize_error_distribution(all_errors, class_errors, class_names):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "   \n",
    "    plt.subplot(2, 2, 1)\n",
    "    error_values = [e['error'] for e in all_errors]\n",
    "    sns.histplot(error_values, kde=True)\n",
    "    plt.xlabel('Error (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Overall Keypoint Error Distribution')\n",
    "    plt.grid(True)\n",
    "   \n",
    "    plt.subplot(2, 2, 2)\n",
    "    for cls, errors in class_errors.items():\n",
    "        if errors:\n",
    "            error_values = [e['error'] for e in errors]\n",
    "            sns.histplot(error_values, kde=True, label=f'Class {class_names[cls]}')\n",
    "    plt.xlabel('Error (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Keypoint Error Distribution by Class')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    keypoint_data = []\n",
    "    keypoint_classes = []\n",
    "    keypoint_indices = []\n",
    "    \n",
    "    for cls, errors in class_errors.items():\n",
    "        for error in errors:\n",
    "            keypoint_data.append(error['error'])\n",
    "            keypoint_classes.append(class_names[cls])\n",
    "            keypoint_indices.append(error['keypoint_idx'])\n",
    "    \n",
    "    error_df = pd.DataFrame({\n",
    "        'Error': keypoint_data,\n",
    "        'Class': keypoint_classes,\n",
    "        'Keypoint': keypoint_indices\n",
    "    })\n",
    "    \n",
    "    sns.boxplot(x='Keypoint', y='Error', data=error_df)\n",
    "    plt.xlabel('Keypoint Index')\n",
    "    plt.ylabel('Error (pixels)')\n",
    "    plt.title('Error Distribution by Keypoint Index')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    for cls, errors in class_errors.items():\n",
    "        if errors:\n",
    "            error_values = [e['error'] for e in errors]\n",
    "            sorted_errors = np.sort(error_values)\n",
    "            p = 1. * np.arange(len(sorted_errors)) / (len(sorted_errors) - 1)\n",
    "            plt.plot(sorted_errors, p, label=f'Class {class_names[cls]}')\n",
    "    \n",
    "    plt.xlabel('Error (pixels)')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.title('Cumulative Distribution of Keypoint Errors')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('keypoint_error_distribution.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    stats = {\n",
    "        'overall': {\n",
    "            'mean': np.mean([e['error'] for e in all_errors]),\n",
    "            'median': np.median([e['error'] for e in all_errors]),\n",
    "            'std': np.std([e['error'] for e in all_errors]),\n",
    "            'min': np.min([e['error'] for e in all_errors]),\n",
    "            'max': np.max([e['error'] for e in all_errors]),\n",
    "            'count': len(all_errors)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for cls, errors in class_errors.items():\n",
    "        if errors:\n",
    "            error_values = [e['error'] for e in errors]\n",
    "            stats[class_names[cls]] = {\n",
    "                'mean': np.mean(error_values),\n",
    "                'median': np.median(error_values),\n",
    "                'std': np.std(error_values),\n",
    "                'min': np.min(error_values),\n",
    "                'max': np.max(error_values),\n",
    "                'count': len(errors)\n",
    "            }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def visualize_keypoint_detection_stats(keypoint_stats, class_names):\n",
    "    plt.figure(figsize=(15, 10))\n",
    " \n",
    "    plt.subplot(2, 2, 1)\n",
    "    categories = ['Total', 'Visible', 'Detected']\n",
    "    values = [\n",
    "        keypoint_stats['total_gt_keypoints'],\n",
    "        keypoint_stats['total_visible_gt_keypoints'],\n",
    "        keypoint_stats['total_detected_keypoints']\n",
    "    ]\n",
    "    \n",
    "    plt.bar(categories, values)\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 5, str(v), ha='center')\n",
    "    \n",
    "    plt.title('Overall Keypoint Statistics')\n",
    "    plt.ylabel('Number of Keypoints')\n",
    "    plt.grid(True, axis='y')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    class_names_list = [class_names[cls] for cls in sorted(class_names.keys())]\n",
    "    x = np.arange(len(class_names_list))\n",
    "    width = 0.25\n",
    "    \n",
    "    totals = [keypoint_stats['class_stats'][cls]['total'] for cls in sorted(class_names.keys())]\n",
    "    visibles = [keypoint_stats['class_stats'][cls]['visible'] for cls in sorted(class_names.keys())]\n",
    "    detecteds = [keypoint_stats['class_stats'][cls]['detected'] for cls in sorted(class_names.keys())]\n",
    "    \n",
    "    plt.bar(x - width, totals, width, label='Total')\n",
    "    plt.bar(x, visibles, width, label='Visible')\n",
    "    plt.bar(x + width, detecteds, width, label='Detected')\n",
    "    \n",
    "    plt.title('Keypoint Statistics by Class')\n",
    "    plt.ylabel('Number of Keypoints')\n",
    "    plt.xticks(x, class_names_list)\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    \n",
    "    overall_detection_rate = keypoint_stats['total_detected_keypoints'] / max(keypoint_stats['total_visible_gt_keypoints'], 1) * 100\n",
    "    class_detection_rates = [\n",
    "        keypoint_stats['class_stats'][cls]['detected'] / max(keypoint_stats['class_stats'][cls]['visible'], 1) * 100\n",
    "        for cls in sorted(class_names.keys())\n",
    "    ]\n",
    "    \n",
    "    all_rates = [overall_detection_rate] + class_detection_rates\n",
    "    all_labels = ['Overall'] + class_names_list\n",
    "    \n",
    "    plt.bar(all_labels, all_rates)\n",
    "    for i, rate in enumerate(all_rates):\n",
    "        plt.text(i, rate + 1, f'{rate:.1f}%', ha='center')\n",
    "    \n",
    "    plt.title('Keypoint Detection Rate')\n",
    "    plt.ylabel('Detection Rate (%)')\n",
    "    plt.ylim(0, 110)\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('keypoint_detection_stats.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'overall_detection_rate': overall_detection_rate,\n",
    "        'class_detection_rates': {class_names[cls]: class_detection_rates[i] for i, cls in enumerate(sorted(class_names.keys()))}\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # 全国大会\n",
    "    model_path = '../../AI_aug_gen/__output__/06_YOLOv8_Pose/1211_leafBlock/yolov8n-pose/20241211-02304455_yolov8n-pose_1211_lb_500_n550_kpt/weights/best.pt'\n",
    "    # WiNF\n",
    "    #model_path = '../../AI_aug_gen/__output__/06_YOLOv8_Pose/cmp_cn_multicn/yolov8n-pose/20240726-16045940_yolov8n-pose_0719_multi_cn_n550_kpt/weights/best.pt'\n",
    "    # 先行研究 2\n",
    "    # model_path = '../../AI_aug_gen/__output__/06_YOLOv8_Pose/cmp_cn_multicn/yolov8n-pose/20240726-06285899_yolov8n-pose_0719_cn_n550_kpt/weights/best.pt'\n",
    "    model = YOLO(model_path)\n",
    "    dataset_path = '../../AI_aug_gen/__dataset__/06_YOLOv8_Pose/1211_leafBlock_500/1211_lb_500_n550_kpt/test/'\n",
    "    class_names = {0: \"クラス0\", 1: \"grape_cane\"}\n",
    "\n",
    "    print('Evaluating model and calculating keypoint errors...')\n",
    "    all_errors, class_errors, details_df, keypoint_stats = evaluate_on_dataset(model, dataset_path)\n",
    "    details_df.to_csv('keypoint_errors_details.csv', index=False)\n",
    "    print('Visualizing error distributions...')\n",
    "    error_stats = visualize_error_distribution(all_errors, class_errors, class_names)\n",
    "    print('Visualizing keypoint detection statistics...')\n",
    "    detection_stats = visualize_keypoint_detection_stats(keypoint_stats, class_names)\n",
    "    print(\"\\n=== Keypoint Detection Statistics ===\")\n",
    "    print(f\"Total ground truth keypoints: {keypoint_stats['total_gt_keypoints']}\")\n",
    "    print(f\"Total visible ground truth keypoints: {keypoint_stats['total_visible_gt_keypoints']}\")\n",
    "    print(f\"Total detected keypoints: {keypoint_stats['total_detected_keypoints']}\")\n",
    "    print(f\"Overall detection rate: {detection_stats['overall_detection_rate']:.2f}%\")\n",
    "    \n",
    "    print(\"\\nClass-wise keypoint statistics:\")\n",
    "    for cls, stats in keypoint_stats['class_stats'].items():\n",
    "        print(f\"  {class_names[cls]}:\")\n",
    "        print(f\"    Total: {stats['total']}\")\n",
    "        print(f\"    Visible: {stats['visible']}\")\n",
    "        print(f\"    Detected: {stats['detected']}\")\n",
    "        print(f\"    Detection rate: {stats['detected'] / max(stats['visible'], 1) * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n=== Keypoint Error Statistics ===\")\n",
    "    print(f\"Overall:\")\n",
    "    print(f\"  Mean Error: {error_stats['overall']['mean']:.2f} pixels\")\n",
    "    print(f\"  Median Error: {error_stats['overall']['median']:.2f} pixels\")\n",
    "    print(f\"  Std Deviation: {error_stats['overall']['std']:.2f} pixels\")\n",
    "    print(f\"  Min Error: {error_stats['overall']['min']:.2f} pixels\")\n",
    "    print(f\"  Max Error: {error_stats['overall']['max']:.2f} pixels\")\n",
    "    print(f\"  Count: {error_stats['overall']['count']} keypoints\")\n",
    "    \n",
    "    for cls_name in [name for name in error_stats.keys() if name != 'overall']:\n",
    "        print(f\"\\n{cls_name}:\")\n",
    "        print(f\"  Mean Error: {error_stats[cls_name]['mean']:.2f} pixels\")\n",
    "        print(f\"  Median Error: {error_stats[cls_name]['median']:.2f} pixels\")\n",
    "        print(f\"  Std Deviation: {error_stats[cls_name]['std']:.2f} pixels\")\n",
    "        print(f\"  Min Error: {error_stats[cls_name]['min']:.2f} pixels\")\n",
    "        print(f\"  Max Error: {error_stats[cls_name]['max']:.2f} pixels\")\n",
    "        print(f\"  Count: {error_stats[cls_name]['count']} keypoints\")\n",
    "    error_stats_rows = []\n",
    "    for category, values in error_stats.items():\n",
    "        row = {'Category': category}\n",
    "        row.update(values)\n",
    "        error_stats_rows.append(row)\n",
    "    \n",
    "    pd.DataFrame(error_stats_rows).to_csv('keypoint_error_stats.csv', index=False)\n",
    "    detection_stats_rows = [\n",
    "        {\n",
    "            'Category': 'Overall',\n",
    "            'Total': keypoint_stats['total_gt_keypoints'],\n",
    "            'Visible': keypoint_stats['total_visible_gt_keypoints'],\n",
    "            'Detected': keypoint_stats['total_detected_keypoints'],\n",
    "            'Detection_Rate': detection_stats['overall_detection_rate']\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for cls in sorted(class_names.keys()):\n",
    "        detection_stats_rows.append({\n",
    "            'Category': class_names[cls],\n",
    "            'Total': keypoint_stats['class_stats'][cls]['total'],\n",
    "            'Visible': keypoint_stats['class_stats'][cls]['visible'],\n",
    "            'Detected': keypoint_stats['class_stats'][cls]['detected'],\n",
    "            'Detection_Rate': keypoint_stats['class_stats'][cls]['detected'] / max(keypoint_stats['class_stats'][cls]['visible'], 1) * 100\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(detection_stats_rows).to_csv('keypoint_detection_stats.csv', index=False)\n",
    "    \n",
    "    print(\"\\nEvaluation complete. Results saved to CSV files and plots.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
