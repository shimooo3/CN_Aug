{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入出力画像の一致度で画像選別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIVE = 0.441 * R - 0.811 * G + 0.385 * B + 18.78745\n",
    "# cive < 0なら緑\n",
    "# civeとExGの共通範囲狭いかも\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def calculate_ExG_ratio(image, mask):\n",
    "    b, g, r = cv2.split(image)\n",
    "    cive = 0.441 * r - 0.811 * g + 0.385 * b + 18.78745\n",
    "    ExG = 2 * g - r - b\n",
    "    condition = (r + g + b > 0) & ((cive > 0) | (ExG < 0))\n",
    "    masked_condition = condition & (mask > 0)\n",
    "    ratio = np.sum(masked_condition) / np.sum(mask > 0)\n",
    "    #print(ratio)\n",
    "    return ratio\n",
    "\n",
    "def process_images(line2line_path, gendata_path):\n",
    "    result = {}\n",
    "    for filename in os.listdir(line2line_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            line2line_img_path = os.path.join(line2line_path, filename)\n",
    "            gendata_img_path = os.path.join(gendata_path, filename)\n",
    "            \n",
    "            if not os.path.exists(gendata_img_path):\n",
    "                print(f\"Warning: {filename} not found in gendata path\")\n",
    "                continue\n",
    "            \n",
    "            line2line_img = cv2.imread(line2line_img_path, 0)\n",
    "            gendata_img = cv2.imread(gendata_img_path)\n",
    "            \n",
    "            if line2line_img is None or gendata_img is None:\n",
    "                print(f\"Warning: Could not read image {filename}\")\n",
    "                continue\n",
    "            \n",
    "            mask = np.uint8(line2line_img > 128)\n",
    "            \n",
    "            if np.sum(mask) == 0:\n",
    "                print(f\"Warning: No white area in mask for {filename}\")\n",
    "                continue\n",
    "            \n",
    "            ratio = calculate_ExG_ratio(gendata_img, mask)\n",
    "            result[filename] = ratio\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_top_100_images(result):\n",
    "    sorted_result = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [filename for filename, _ in sorted_result[:100]]\n",
    "    # return [filename for filename, _  in sorted_result[-100:]] # 逆順\n",
    "    #50-100\n",
    "    #return [filename for filename, _ in sorted_result[50:100]]\n",
    "    # return [filename for filename, _ in sorted_result[-100:-50]]\n",
    "\n",
    "\n",
    "def get_image_ids(json_file, top_100_images):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    image_id_map = {img['file_name']: img['id'] for img in data['images']}\n",
    "    return [image_id_map[img] for img in top_100_images if img in image_id_map]\n",
    "\n",
    "def main():\n",
    "    num_list = [\"01\", \"02\", \"03\", \"04\", \"05\"]\n",
    "    for num in num_list:\n",
    "        line2line_path = f\"../images/no_extend/{num}/line2line/\"\n",
    "        gendata_path = f\"../images/gen_data/output/0718_best/multi_controlnet/{num}/\"\n",
    "        # line2line_path = f\"../images/test2/{num}/line2line/\"\n",
    "        # gendata_path = f\"../images/gen_data/output/1209/leaf_block_mcn/{num}/\"\n",
    "        gendata_json = f\"../images/gen_data/{num}_gen_coco.json\"\n",
    "        \n",
    "        result = process_images(line2line_path, gendata_path)\n",
    "        \n",
    "        top_100_images = get_top_100_images(result)\n",
    "        image_ids = get_image_ids(gendata_json, top_100_images)\n",
    "        \n",
    "        output_file = f\"../ids/select_ExG/top_100_{num}.txt\"\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(','.join(map(str, image_ids)))\n",
    "        \n",
    "        print(f\"{num} Done\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ペアに対してExG<0&&CIVE<0の領域抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ExG_CIVE(image):\n",
    "    b, g, r = cv2.split(image)\n",
    "    b = b.astype(float)\n",
    "    g = g.astype(float)\n",
    "    r = r.astype(float)\n",
    "    \n",
    "    cive = 0.441 * r - 0.811 * g + 0.385 * b + 18.78745\n",
    "    ExG = 2 * g - r - b\n",
    "    \n",
    "    return ExG, cive\n",
    "\n",
    "def process_image_pair(line2line_path, gendata_path, output_path):\n",
    "    # 線画（マスク）画像を読み込む\n",
    "    line2line_img = cv2.imread(line2line_path, 0)\n",
    "    \n",
    "    # 生成データ（カラー）画像を読み込む\n",
    "    gendata_img = cv2.imread(gendata_path)\n",
    "    \n",
    "    if line2line_img is None or gendata_img is None:\n",
    "        print(\"エラー: 画像を読み込めませんでした。\")\n",
    "        return\n",
    "    \n",
    "    # マスクを作成（白い領域を抽出）\n",
    "    mask = np.uint8(line2line_img > 128)\n",
    "    \n",
    "    # ExGとCIVEを計算\n",
    "    ExG, cive = calculate_ExG_CIVE(gendata_img)\n",
    "    result = np.zeros_like(gendata_img)\n",
    "    condition = (mask > 0) & (cive > 0)\n",
    "    masked_condition = condition & (mask > 0)\n",
    "    ratio = np.sum(masked_condition) / np.sum(mask > 0)\n",
    "    result[condition] = [255, 255, 255]\n",
    "    print(ratio)\n",
    "    \n",
    "    \n",
    "    # 結果を保存\n",
    "    cv2.imwrite(output_path, result)\n",
    "    \n",
    "    print(f\"処理完了: 結果を {output_path} に保存しました。\")\n",
    "\n",
    "# 使用例\n",
    "bw_image_path = '../images/test2/01/line2line/01_68_generate_image.jpg'\n",
    "#color_image_path = '../images/gen_data/output/0718_best/multi_controlnet/01/01_0_generate_image.jpg'\n",
    "color_image_path = '../images/gen_data/output/1209/leaf_block_mcn/01/01_68_generate_image.jpg'\n",
    "output_path = './output.jpg'\n",
    "process_image_pair(bw_image_path, color_image_path, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "横軸：割合，縦軸：枚数のグラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_ExG_ratio(image, mask):\n",
    "    b, g, r = cv2.split(image)\n",
    "    cive = 0.441 * r - 0.811 * g + 0.385 * b + 18.78745\n",
    "    ExG = 2 * g - r - b\n",
    "    condition = (r + g + b > 0) & ((cive > 0) | (ExG < 0))\n",
    "    masked_condition = condition & (mask > 0)\n",
    "    ratio = np.sum(masked_condition) / np.sum(mask > 0)\n",
    "    return ratio\n",
    "\n",
    "def process_images(line2line_path, gendata_path):\n",
    "    result = {}\n",
    "    for filename in os.listdir(line2line_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            line2line_img_path = os.path.join(line2line_path, filename)\n",
    "            gendata_img_path = os.path.join(gendata_path, filename)\n",
    "            \n",
    "            if not os.path.exists(gendata_img_path):\n",
    "                print(f\"Warning: {filename} not found in gendata path\")\n",
    "                continue\n",
    "            \n",
    "            line2line_img = cv2.imread(line2line_img_path, 0)\n",
    "            gendata_img = cv2.imread(gendata_img_path)\n",
    "            \n",
    "            if line2line_img is None or gendata_img is None:\n",
    "                print(f\"Warning: Could not read image {filename}\")\n",
    "                continue\n",
    "            \n",
    "            mask = np.uint8(line2line_img > 128)\n",
    "            \n",
    "            if np.sum(mask) == 0:\n",
    "                print(f\"Warning: No white area in mask for {filename}\")\n",
    "                continue\n",
    "            \n",
    "            ratio = calculate_ExG_ratio(gendata_img, mask)\n",
    "            result[filename] = ratio\n",
    "    \n",
    "    return result\n",
    "\n",
    "def plot_line_and_histogram(all_ratios_list, labels):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    bin_edges = np.arange(0, 1.1, 0.1)\n",
    "    colors = ['blue', 'red']\n",
    "    \n",
    "    for ratios, label in zip(all_ratios_list, labels):\n",
    "        hist, _ = np.histogram(ratios, bins=bin_edges)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        \n",
    "        # Plot histogram alpha=で透過率をいじる\n",
    "        plt.bar(bin_centers, hist, width=0.08, color=colors, label=label)\n",
    "        \n",
    "        # Plot line graph\n",
    "        plt.plot(bin_centers, hist, marker='o', label=label, linewidth=6, markersize=15)\n",
    "    \n",
    "    plt.xlabel('Ratio', fontsize=20)\n",
    "    plt.ylabel('Number of Images', fontsize=20)\n",
    "    # plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    # plt.title('Distribution of Image Ratios', y=-0.12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, plt.ylim()[1])\n",
    "\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    plt.gca().set_aspect('auto', adjustable='box')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    num_list = [\"01\", \"02\", \"03\", \"04\", \"05\"]\n",
    "    gendata_paths = [\n",
    "    (\"../images/gen_data/output/0718_best/multi_controlnet/\", \" \"),\n",
    "    (\"../images/gen_data/output/0718_best/controlnet/\", \" \")\n",
    "    ]\n",
    "\n",
    "    all_ratios_list = []\n",
    "    labels = []\n",
    "\n",
    "    for gendata_path, label in gendata_paths:\n",
    "        all_ratios = []\n",
    "\n",
    "        for num in num_list:\n",
    "            line2line_path = f\"../images/no_extend/{num}/line2line/\"\n",
    "            current_gendata_path = os.path.join(gendata_path, num)\n",
    "            \n",
    "            result = process_images(line2line_path, current_gendata_path)\n",
    "            all_ratios.extend(result.values())\n",
    "            \n",
    "            print(f\"{num} Done\")\n",
    "\n",
    "        all_ratios_list.append(all_ratios)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Plot line graphs and histograms for all ratios\n",
    "    labels = [\"ours\", \"prior\"]\n",
    "    plot_line_and_histogram(all_ratios_list, labels)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_ExG_ratio(image, mask):\n",
    "    b, g, r = cv2.split(image)\n",
    "    cive = 0.441 * r - 0.811 * g + 0.385 * b + 18.78745\n",
    "    ExG = 2 * g - r - b\n",
    "    condition = (r + g + b > 0) & ((cive > 0) | (ExG < 0))\n",
    "    masked_condition = condition & (mask > 0)\n",
    "    ratio = np.sum(masked_condition) / np.sum(mask > 0)\n",
    "    return ratio\n",
    "\n",
    "def process_images(line2line_path, gendata_path):\n",
    "    result = {}\n",
    "    for filename in os.listdir(line2line_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            line2line_img_path = os.path.join(line2line_path, filename)\n",
    "            gendata_img_path = os.path.join(gendata_path, filename)\n",
    "            \n",
    "            if not os.path.exists(gendata_img_path):\n",
    "                print(f\"Warning: {filename} not found in gendata path\")\n",
    "                continue\n",
    "            \n",
    "            line2line_img = cv2.imread(line2line_img_path, 0)\n",
    "            gendata_img = cv2.imread(gendata_img_path)\n",
    "            \n",
    "            if line2line_img is None or gendata_img is None:\n",
    "                print(f\"Warning: Could not read image {filename}\")\n",
    "                continue\n",
    "            \n",
    "            mask = np.uint8(line2line_img > 128)\n",
    "            \n",
    "            if np.sum(mask) == 0:\n",
    "                print(f\"Warning: No white area in mask for {filename}\")\n",
    "                continue\n",
    "            \n",
    "            ratio = calculate_ExG_ratio(gendata_img, mask)\n",
    "            result[filename] = ratio\n",
    "    \n",
    "    return result\n",
    "\n",
    "def plot_line_and_histogram(all_ratios_list, labels):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    bin_edges = np.arange(0, 1.1, 0.1)\n",
    "    colors = ['#CC6677', '#4477AA']  # 論文に適した色を設定\n",
    "    \n",
    "    # ヒストグラムを重ねて表示するため、透明度を調整\n",
    "    alphas = [0.5, 0.5]\n",
    "    bar_width = 0.09\n",
    "    \n",
    "    for i, (ratios, label) in enumerate(zip(all_ratios_list, labels)):\n",
    "        hist, _ = np.histogram(ratios, bins=bin_edges)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        \n",
    "        # ヒストグラム描画（重ね合わせ）\n",
    "        plt.bar(bin_centers, hist, width=bar_width, alpha=alphas[i], \n",
    "                color=colors[i], edgecolor=colors[i], linewidth=1.5, label=f\"{label} (Hist)\")\n",
    "        \n",
    "        # 同じデータに対して折れ線グラフを描画\n",
    "        plt.plot(bin_centers, hist, marker='o', color=colors[i], \n",
    "                linewidth=3, markersize=10, label=f\"{label} (Line)\")\n",
    "    \n",
    "    plt.xlabel('Ratio', fontsize=20)\n",
    "    plt.ylabel('Num Images', fontsize=20)\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, plt.ylim()[1] * 1.1)  # 上限に少し余裕を持たせる\n",
    "\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 論文用に高品質な画像として保存\n",
    "    plt.savefig('ratio_comparison.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.savefig('ratio_comparison.png', format='png', bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    num_list = [\"01\", \"02\", \"03\", \"04\", \"05\"]\n",
    "    gendata_paths = [\n",
    "    (\"../images/gen_data/output/0718_best/multi_controlnet/\", \"Multi ControlNet\"),\n",
    "    (\"../images/gen_data/output/0718_best/controlnet/\", \"ControlNet\")\n",
    "    ]\n",
    "\n",
    "    all_ratios_list = []\n",
    "    labels = []\n",
    "\n",
    "    for gendata_path, label in gendata_paths:\n",
    "        all_ratios = []\n",
    "\n",
    "        for num in num_list:\n",
    "            line2line_path = f\"../images/no_extend/{num}/line2line/\"\n",
    "            current_gendata_path = os.path.join(gendata_path, num)\n",
    "            \n",
    "            result = process_images(line2line_path, current_gendata_path)\n",
    "            all_ratios.extend(result.values())\n",
    "            \n",
    "            print(f\"{num} Done\")\n",
    "\n",
    "        all_ratios_list.append(all_ratios)\n",
    "        labels.append(label)\n",
    "\n",
    "    # 重ね合わせヒストグラムと折れ線グラフをプロット\n",
    "    labels = [\"ours\", \"prior\"]\n",
    "    plot_line_and_histogram(all_ratios_list, labels)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(CIVE | U-Net) & mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# ==========================================\n",
    "# 1. Model Definitions (from predict_reconU.py)\n",
    "# ==========================================\n",
    "\n",
    "class ReconstructionDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2, mode='nearest'), # H/4\n",
    "            torch.nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2, mode='nearest'), # H/2\n",
    "            torch.nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2, mode='nearest'), # H\n",
    "            torch.nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # H -> H/2\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # H/2 -> H/4\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # H/4 -> H/8\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # H/8 -> H/8\n",
    "            nn.Conv2d(256, 320, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class CompositionUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = ReconstructionDecoder(in_channels=320, out_channels=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "\n",
    "# ==========================================\n",
    "# 2. Processing Logic\n",
    "# ==========================================\n",
    "\n",
    "def calculate_combined_ratio(image_cv2, mask_cv2, model, device, unet_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate ratio using: [(CIVE) OR (UNet)] AND (Mask)\n",
    "    \"\"\"\n",
    "    original_h, original_w = image_cv2.shape[:2]\n",
    "\n",
    "    # --- 1. CIVE Calculation (on original size) ---\n",
    "    # OpenCV loads as BGR\n",
    "    b, g, r = cv2.split(image_cv2)\n",
    "    # CIVE formula (Negative values typically indicate green vegetation)\n",
    "    # Assuming < 0 is branch/vegetation based on standard CIVE usage\n",
    "    cive = 0.441 * r - 0.811 * g + 0.385 * b + 18.78745\n",
    "    cive_binary = (cive > 0) # Boolean mask: True where branch\n",
    "\n",
    "    # --- 2. U-Net Prediction ---\n",
    "    # Convert BGR to RGB for PIL/Model\n",
    "    img_rgb = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "    \n",
    "    # Resize to 512x512 for the model input\n",
    "    process_size = 512\n",
    "    img_resized = pil_img.resize((process_size, process_size), Image.BILINEAR)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    input_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor)\n",
    "    \n",
    "    # Process output\n",
    "    unet_output = output_tensor.squeeze().cpu().numpy()\n",
    "    unet_binary_small = (unet_output > unet_threshold)\n",
    "    \n",
    "    # Resize UNet output back to original image size to match CIVE and Mask\n",
    "    # Using PIL for resizing mask (Nearest Neighbor to keep binary nature)\n",
    "    unet_img_small = Image.fromarray((unet_binary_small * 255).astype(np.uint8), mode='L')\n",
    "    unet_img_original = unet_img_small.resize((original_w, original_h), Image.NEAREST)\n",
    "    unet_binary = np.array(unet_img_original) > 128 # Boolean mask\n",
    "\n",
    "    # --- 3. Combine Logic ---\n",
    "    # Target: (CIVE or UNet)\n",
    "    combined_prediction = cive_binary | unet_binary\n",
    "\n",
    "    # --- 4. Apply Mask (line2line) ---\n",
    "    # Mask from line2line (white area is valid)\n",
    "    valid_area_mask = mask_cv2 > 128\n",
    "    \n",
    "    # Final extraction: Prediction AND Mask\n",
    "    final_extraction = combined_prediction & valid_area_mask\n",
    "\n",
    "    # Calculate Ratio\n",
    "    # Ratio = (Extracted Area) / (Total Mask Area)\n",
    "    mask_pixel_count = np.sum(valid_area_mask)\n",
    "    \n",
    "    if mask_pixel_count == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    ratio = np.sum(final_extraction) / mask_pixel_count\n",
    "    return ratio\n",
    "\n",
    "def process_images(line2line_path, gendata_path, model, device):\n",
    "    result = {}\n",
    "    \n",
    "    # Get list of files\n",
    "    if not os.path.exists(line2line_path):\n",
    "        print(f\"Error: Path not found {line2line_path}\")\n",
    "        return result\n",
    "\n",
    "    files = [f for f in os.listdir(line2line_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "    \n",
    "    for filename in files:\n",
    "        line2line_img_path = os.path.join(line2line_path, filename)\n",
    "        gendata_img_path = os.path.join(gendata_path, filename)\n",
    "        \n",
    "        # Check if corresponding generated image exists\n",
    "        if not os.path.exists(gendata_img_path):\n",
    "            # Try checking if extensions differ (jpg vs png)\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            potential_path = os.path.join(gendata_path, base_name + \".png\")\n",
    "            if os.path.exists(potential_path):\n",
    "                gendata_img_path = potential_path\n",
    "            else:\n",
    "                potential_path = os.path.join(gendata_path, base_name + \".jpg\")\n",
    "                if os.path.exists(potential_path):\n",
    "                    gendata_img_path = potential_path\n",
    "                else:\n",
    "                    # print(f\"Warning: {filename} not found in gendata path\")\n",
    "                    continue\n",
    "        \n",
    "        # Read images\n",
    "        # line2line (mask) is grayscale\n",
    "        line2line_img = cv2.imread(line2line_img_path, 0) \n",
    "        # gendata (target) is color\n",
    "        gendata_img = cv2.imread(gendata_img_path)\n",
    "        \n",
    "        if line2line_img is None or gendata_img is None:\n",
    "            print(f\"Warning: Could not read image pair for {filename}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate ratio with the new logic\n",
    "        ratio = calculate_combined_ratio(gendata_img, line2line_img, model, device)\n",
    "        result[filename] = ratio\n",
    "    \n",
    "    return result\n",
    "\n",
    "def plot_line_and_histogram(all_ratios_list, labels):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    bin_edges = np.arange(0, 1.1, 0.1)\n",
    "    # colors = ['#CC6677', '#4477AA', '#DDCC77', '#117733'] # 必要に応じて色を追加\n",
    "    colors = ['#CC6677', '#4477AA']\n",
    "    \n",
    "    alphas = [0.5, 0.5]\n",
    "    bar_width = 0.09\n",
    "    \n",
    "    for i, (ratios, label) in enumerate(zip(all_ratios_list, labels)):\n",
    "        color = colors[i % len(colors)]\n",
    "        hist, _ = np.histogram(ratios, bins=bin_edges)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        \n",
    "        # ヒストグラム描画\n",
    "        plt.bar(bin_centers, hist, width=bar_width, alpha=alphas[i % len(alphas)], \n",
    "                color=color, edgecolor=color, linewidth=1.5, label=f\"{label} (Hist)\")\n",
    "        \n",
    "        # 折れ線グラフ描画\n",
    "        plt.plot(bin_centers, hist, marker='o', color=color, \n",
    "                linewidth=3, markersize=10, label=f\"{label} (Line)\")\n",
    "    \n",
    "    plt.xlabel('Ratio', fontsize=20)\n",
    "    plt.ylabel('Num Images', fontsize=20)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, plt.ylim()[1] * 1.1) \n",
    "\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('ratio_comparison_unet_cive.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.savefig('ratio_comparison_unet_cive.png', format='png', bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 3. Main Execution\n",
    "# ==========================================\n",
    "\n",
    "def main():\n",
    "    # --- Hardcoded Paths ---\n",
    "    # モデルの重みパス (環境に合わせて修正してください)\n",
    "    MODEL_WEIGHTS_PATH = \"../_models/UNet_decoder/model_epoch_19587_loss_0.0065.pth\"\n",
    "    \n",
    "    # データセットの設定\n",
    "    num_list = [\"01\", \"02\", \"03\", \"04\", \"05\"]\n",
    "    # num_list = [\"01\"]\n",
    "\n",
    "    \n",
    "    gendata_paths = [\n",
    "        (\"../images/gen_data/output/1026_day01/\", \"Decoder\"),\n",
    "        (\"../images/gen_data/output/1026_hiraharaDay/\", \"ControlNet\")\n",
    "    ]\n",
    "    \n",
    "    # --- Load Model Once ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = CompositionUNet()\n",
    "    if os.path.exists(MODEL_WEIGHTS_PATH):\n",
    "        print(f\"Loading model weights from {MODEL_WEIGHTS_PATH}\")\n",
    "        # マップロケーションを指定してGPU/CPU間のロードエラーを防ぐ\n",
    "        state_dict = torch.load(MODEL_WEIGHTS_PATH, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print(f\"Error: Model weights not found at {MODEL_WEIGHTS_PATH}\")\n",
    "        # テスト用にダミー動作させる場合はここでreturnせず続行も可能ですが、通常は停止\n",
    "        return\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # --- Process Data ---\n",
    "    all_ratios_list = []\n",
    "    labels = []\n",
    "\n",
    "    for gendata_path_root, label in gendata_paths:\n",
    "        all_ratios = []\n",
    "\n",
    "        for num in num_list:\n",
    "            line2line_path = f\"../images/no_extend/{num}/line2line/\"\n",
    "            current_gendata_path = os.path.join(gendata_path_root, num)\n",
    "            \n",
    "            print(f\"Processing: {label} - {num}...\")\n",
    "            result = process_images(line2line_path, current_gendata_path, model, device)\n",
    "            all_ratios.extend(result.values())\n",
    "            \n",
    "            print(f\"  -> Processed {len(result)} images.\")\n",
    "\n",
    "        all_ratios_list.append(all_ratios)\n",
    "        labels.append(label)\n",
    "\n",
    "    # --- Plot Results ---\n",
    "    if any(len(x) > 0 for x in all_ratios_list):\n",
    "        plot_line_and_histogram(all_ratios_list, labels)\n",
    "    else:\n",
    "        print(\"No data found to plot.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ymc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
