{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 枝領域の編集とRGB平面分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. CIVE値に基づくセグメンテーションマスクの修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_json_with_cive(json_path, image_dir, output_dir='output'):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    new_coco_data = coco_data.copy()\n",
    "    new_annotations = []\n",
    "\n",
    "    for img_info in coco_data['images']:\n",
    "        image_id = img_info['id']\n",
    "        file_name = img_info['file_name']\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f'画像ファイルが見つかりません: {image_path}')\n",
    "            continue\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        width, height = image.size\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        img_annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] == image_id]\n",
    "\n",
    "        for ann in img_annotations:\n",
    "            new_ann = ann.copy()\n",
    "            new_segments = []\n",
    "\n",
    "            for seg in ann['segmentation']:\n",
    "                if not isinstance(seg, list) or len(seg) < 6:\n",
    "                    continue\n",
    "\n",
    "                mask = Image.new('L', (width, height), 0)\n",
    "                draw = ImageDraw.Draw(mask)\n",
    "                draw.polygon(seg, outline=1, fill=1)\n",
    "                mask_np = np.array(mask, dtype=np.uint8)\n",
    "\n",
    "                pixels_in_mask = img_np[mask_np == 1]\n",
    "\n",
    "                r = pixels_in_mask[:, 0].astype(np.float64)\n",
    "                g = pixels_in_mask[:, 1].astype(np.float64)\n",
    "                b = pixels_in_mask[:, 2].astype(np.float64)\n",
    "                cive = 0.441 * r - 0.811 * g + 0.385 * b + 18.78745\n",
    "\n",
    "                leaf_pixels_mask = cive < 0\n",
    "                original_indices = np.where(mask_np == 1)\n",
    "                leaf_coords = (original_indices[0][leaf_pixels_mask], original_indices[1][leaf_pixels_mask])\n",
    "                mask_np[leaf_coords] = 0\n",
    "\n",
    "                contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                for contour in contours:\n",
    "                    if contour.size >= 6: \n",
    "                        new_segments.append(contour.flatten().tolist())\n",
    "            \n",
    "            if new_segments:\n",
    "                new_ann['segmentation'] = new_segments\n",
    "                new_annotations.append(new_ann)\n",
    "\n",
    "    new_coco_data['annotations'] = new_annotations\n",
    "\n",
    "    new_json_path = os.path.join(output_dir, 'edited_' + os.path.basename(json_path))\n",
    "    with open(new_json_path, 'w') as f:\n",
    "        json.dump(new_coco_data, f, indent=4)\n",
    "        \n",
    "    print(f'処理が完了しました。新しいJSONファイルが保存されました: {new_json_path}')\n",
    "    return new_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_path = './test_day_08/test_day_08.json'\n",
    "input_image_dir = './test_day_08/'\n",
    "output_dir_cive = 'cive_output'\n",
    "\n",
    "edited_json_path = edit_json_with_cive(input_json_path, input_image_dir, output_dir_cive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. 更新されたセグメンテーションの視覚的確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(json_path, image_dir, num_images=5, random_selection=True):\n",
    "    \"\"\"\n",
    "    JSONファイルのアノテーションを画像に描画して視覚的に確認する。\n",
    "    \n",
    "    Args:\n",
    "        json_path (str): COCO形式のJSONファイルのパス。\n",
    "        image_dir (str): 画像が格納されているディレクトリのパス。\n",
    "        num_images (int): 表示する画像の最大数。\n",
    "        random_selection (bool): ランダムに画像を選ぶか、先頭から順に選ぶか。\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    image_id_to_info = {img['id']: img for img in coco_data['images']}\n",
    "\n",
    "    image_id_to_anns = {} \n",
    "    for ann in coco_data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in image_id_to_anns:\n",
    "            image_id_to_anns[img_id] = []\n",
    "        image_id_to_anns[img_id].append(ann)\n",
    "\n",
    "    annotated_image_ids = list(image_id_to_anns.keys())\n",
    "    if random_selection:\n",
    "        selected_ids = np.random.choice(annotated_image_ids, min(num_images, len(annotated_image_ids)), replace=False)\n",
    "    else:\n",
    "        selected_ids = annotated_image_ids[:num_images]\n",
    "\n",
    "    for img_id in selected_ids:\n",
    "        img_info = image_id_to_info.get(img_id)\n",
    "        if not img_info:\n",
    "            continue\n",
    "\n",
    "        file_name = img_info['file_name']\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f'画像が見つかりません: {image_path}')\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        overlay = image.copy()\n",
    "\n",
    "        anns = image_id_to_anns[img_id]\n",
    "        for ann in anns:\n",
    "            for seg in ann['segmentation']:\n",
    "                if isinstance(seg, list) and len(seg) >= 6:\n",
    "                    poly = np.array(seg).reshape((-1, 2)).astype(np.int32)\n",
    "                    cv2.fillPoly(overlay, [poly], color=(255, 0, 0))\n",
    "\n",
    "        alpha = 0.4\n",
    "        image_with_mask = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.imshow(image_with_mask)\n",
    "        plt.title(f'Image: {file_name} (ID: {img_id})')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_visualize = edited_json_path \n",
    "image_dir_to_visualize = input_image_dir\n",
    "\n",
    "visualize_segmentation(json_to_visualize, image_dir_to_visualize, num_images=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 3. 枝領域を分離するRGB平面式の算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rgb_plane(json_path, image_dir):\n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    branch_pixels = []\n",
    "    other_pixels = []\n",
    "\n",
    "    for img_info in coco_data['images']:\n",
    "        image_id = img_info['id']\n",
    "        file_name = img_info['file_name']\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f'画像ファイルが見つかりません: {image_path}')\n",
    "            continue\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        width, height = image.size\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        full_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        img_annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] == image_id]\n",
    "\n",
    "        for ann in img_annotations:\n",
    "            for seg in ann['segmentation']:\n",
    "                if isinstance(seg, list) and len(seg) >= 6:\n",
    "                    poly = np.array(seg).reshape((-1, 2)).astype(np.int32)\n",
    "                    cv2.fillPoly(full_mask, [poly], 1)\n",
    "\n",
    "        branch_pixels.extend(img_np[full_mask == 1].tolist())\n",
    "        other_pixels.extend(img_np[full_mask == 0].tolist())\n",
    "\n",
    "    if not branch_pixels or not other_pixels:\n",
    "        print('枝領域または非枝領域のデータが収集できませんでした。')\n",
    "        return\n",
    "\n",
    "    X = np.array(branch_pixels + other_pixels)\n",
    "    y = np.array([1] * len(branch_pixels) + [0] * len(other_pixels)) # 1: 枝, 0: その他\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    coef = model.coef_[0]  # w1, w2, w3\n",
    "    intercept = model.intercept_[0] # w0\n",
    "    equation = f'{coef[0]:.4f} * R + {coef[1]:.4f} * G + {coef[2]:.4f} * B + {intercept:.4f} = 0'\n",
    "    print('算出されたRGB平面式:')\n",
    "    print(equation)\n",
    "\n",
    "    return equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_for_plane = edited_json_path\n",
    "input_image_dir_for_plane = input_image_dir\n",
    "\n",
    "plane_equation = calculate_rgb_plane(input_json_for_plane, input_image_dir_for_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3-2. 損失関数の変更+pytorchによるロジスティクス回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "json_path = \"./train/train.json\"\n",
    "image_dir = \"./train/\"\n",
    "\n",
    "\n",
    "# \"BCEWithLogits\" (推奨), \"BCE\", \"MSE\", \"GCE\"\n",
    "loss_function_name = \"BCEWithLogits\"\n",
    "gce_q_param = 0.7\n",
    "\n",
    "# Early Stopping\n",
    "patience = 5\n",
    "delta = 0.0001\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "batch_size = 1024\n",
    "pixels_per_image = 2000\n",
    "validation_split = 0.2\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    検証データの損失が改善しなくなったら学習を早期に終了させるためのクラス。\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''検証損失が改善した場合にモデルを保存する'''\n",
    "        print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "class GCELoss(nn.Module):\n",
    "    def __init__(self, q=0.7):\n",
    "        super(GCELoss, self).__init__()\n",
    "        self.q = q\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        p_t = targets * probs + (1 - targets) * (1 - probs)\n",
    "        loss = (1 - (p_t + 1e-8) ** self.q) / self.q\n",
    "        return loss.mean()\n",
    "\n",
    "class CocoSegmentationPixelDataset(Dataset):\n",
    "    def __init__(self, json_path, image_dir, pixels_per_image=1000):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.pixels_per_image = pixels_per_image\n",
    "        self.pixels, self.labels = [], []\n",
    "        print(\"Parsing COCO JSON file manually...\")\n",
    "        with open(json_path, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "        self._img_infos = {img['id']: img for img in coco_data['images']}\n",
    "        self._img_to_anns = {img_id: [] for img_id in self._img_infos}\n",
    "        for ann in coco_data['annotations']:\n",
    "            if 'segmentation' in ann and ann['segmentation']:\n",
    "                self._img_to_anns[ann['image_id']].append(ann)\n",
    "        self.img_ids = list(self._img_infos.keys())\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _create_mask_from_annotations(self, height, width, annotations):\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        for ann in annotations:\n",
    "            for seg_poly in ann['segmentation']:\n",
    "                poly = np.array(seg_poly, dtype=np.int32).reshape((-1, 2))\n",
    "                cv2.fillPoly(mask, [poly], 1)\n",
    "        return mask\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        print(\"Preparing pixel dataset...\")\n",
    "        for img_id in self.img_ids:\n",
    "            img_info = self._img_infos[img_id]\n",
    "            img_path = self.image_dir / img_info['file_name']\n",
    "            if not img_path.exists(): continue\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image_np = np.array(image)\n",
    "            annotations = self._img_to_anns.get(img_id, [])\n",
    "            if not annotations: continue\n",
    "            mask = self._create_mask_from_annotations(img_info['height'], img_info['width'], annotations)\n",
    "            pixels = image_np.reshape(-1, 3); labels = mask.reshape(-1)\n",
    "            num_pixels_total = pixels.shape[0]\n",
    "            sample_indices = random.sample(range(num_pixels_total), min(num_pixels_total, self.pixels_per_image))\n",
    "            self.pixels.append(torch.from_numpy(pixels[sample_indices]).float() / 255.0)\n",
    "            self.labels.append(torch.from_numpy(labels[sample_indices]).float())\n",
    "        if self.pixels and self.labels:\n",
    "            self.pixels = torch.cat(self.pixels, dim=0)\n",
    "            self.labels = torch.cat(self.labels, dim=0).unsqueeze(1)\n",
    "            print(f\"Dataset prepared. Total sampled pixels: {len(self.pixels)}\")\n",
    "        else: print(\"Warning: No valid data could be prepared.\")\n",
    "\n",
    "    def __len__(self): return len(self.pixels)\n",
    "    def __getitem__(self, idx): return self.pixels[idx], self.labels[idx]\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "    def forward(self, x): return self.linear(x)\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs, early_stopping):\n",
    "    \"\"\"モデルの学習を行う（Early Stopping対応）\"\"\"\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader)\n",
    "        epoch_valid_loss = valid_loss / len(valid_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.6f}, Valid Loss: {epoch_valid_loss:.6f}\")\n",
    "        \n",
    "        early_stopping(epoch_valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print(\"Loading best model weights...\")\n",
    "    model.load_state_dict(torch.load(early_stopping.path))\n",
    "\n",
    "dataset = CocoSegmentationPixelDataset(\n",
    "    json_path=json_path, image_dir=image_dir, pixels_per_image=pixels_per_image\n",
    ")\n",
    "\n",
    "if len(dataset) > 0:\n",
    "    dataset_size = len(dataset)\n",
    "    val_size = int(np.floor(validation_split * dataset_size))\n",
    "    train_size = dataset_size - val_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    print(f\"Training on {len(train_dataset)} samples, validating on {len(val_dataset)} samples.\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    base_model = LogisticRegressionModel()\n",
    "\n",
    "    loss_functions = {\n",
    "        \"BCEWithLogits\": (nn.BCEWithLogitsLoss(), copy.deepcopy(base_model)),\n",
    "        \"GCE\": (GCELoss(gce_q_param), copy.deepcopy(base_model)),\n",
    "        \"BCE\": (nn.BCELoss(), nn.Sequential(base_model, nn.Sigmoid())),\n",
    "        \"MSE\": (nn.MSELoss(), nn.Sequential(base_model, nn.Sigmoid())),\n",
    "        \"MAE\": (nn.L1Loss(), nn.Sequential(base_model, nn.Sigmoid()))\n",
    "    }\n",
    "    \n",
    "    if loss_function_name not in loss_functions:\n",
    "        raise ValueError(f\"Unknown loss function: {loss_function_name}. Available options: {list(loss_functions.keys())}\")\n",
    "\n",
    "    criterion, model = loss_functions[loss_function_name]\n",
    "    print(f\"Using loss function: {loss_function_name}\")\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    early_stopping = EarlyStopping(patience=patience, delta=delta)\n",
    "\n",
    "    train_model(model, train_loader, valid_loader, criterion, optimizer, epochs, early_stopping)\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "    if isinstance(model, nn.Sequential):\n",
    "        weights = model[0].linear.weight.squeeze()\n",
    "        bias = model[0].linear.bias.squeeze()\n",
    "    else:\n",
    "        weights = model.linear.weight.squeeze()\n",
    "        bias = model.linear.bias.squeeze()\n",
    "\n",
    "    w_r, w_g, w_b = weights[0].item(), weights[1].item(), weights[2].item()\n",
    "    b = bias.item()\n",
    "\n",
    "    print(\"Learned Parameters (from best model):\")\n",
    "    print(f\"  Weight_R: {w_r:.6f}\\n  Weight_G: {w_g:.6f}\\n  Weight_B: {w_b:.6f}\\n  Bias: {b:.6f}\")\n",
    "    \n",
    "    print(\"\\n--- RGB Separation Plane Equation ---\")\n",
    "    print(f\"Equation: ({w_r:.6f})*R + ({w_g:.6f})*G + ({w_b:.6f})*B + ({b:.6f}) = 0\")\n",
    "    print(\"\\nA pixel (R,G,B) is classified as part of the segmentation if the result of the equation is > 0.\")\n",
    "else:\n",
    "    print(\"No data to train on. Exiting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 4. RGB平面式による二値化の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例: 画像一枚に対してRGBの式を適用し，0を境界値として二値化し，図示\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 画像パスを指定（例: 'sample.jpg'）\n",
    "img_path = './train/NON0344_960x1280_2640.jpg'  # 適宜パスを変更\n",
    "img = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "r = img_rgb[:,:,0]\n",
    "g = img_rgb[:,:,1]\n",
    "b = img_rgb[:,:,2]\n",
    "\n",
    "# night\n",
    "rgb_formula_day = 0.0884 * r + -0.0785 * g + -0.0025 * b + -4.8992\n",
    "# day\n",
    "rgb_formula_night = 0.0843 * r + -0.1429 * g + 0.0337 * b + -0.6300\n",
    "\n",
    "\n",
    "# 0を境界値として二値化\n",
    "binary_img = np.where((rgb_formula_day > 0) | (rgb_formula_night > 0), 255, 0).astype(np.uint8)\n",
    "\n",
    "# 図示\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Original')\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Binarized (R-G-B > 0)')\n",
    "plt.imshow(binary_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caneRGB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
